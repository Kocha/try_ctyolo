input, output, weight, layer
  8,   8,   0, input_1
  8,   8,   8, conv2d_1
  8,   8,   8, batch_normalization_1
  8,   8,   8, leaky_re_lu_1
  8,   8,   8, max_pooling2d_1
  8,   8,   8, conv2d_2
  8,   8,   8, batch_normalization_2
  8,   8,   8, leaky_re_lu_2
  8,   8,   8, max_pooling2d_2
  8,   8,   8, conv2d_3
  8,   8,   8, batch_normalization_3
  8,   8,   8, leaky_re_lu_3
  8,   8,   8, max_pooling2d_3
  8,   8,   8, conv2d_4
  8,   8,   8, batch_normalization_4
  8,   8,   8, leaky_re_lu_4
  8,   8,   8, max_pooling2d_4
  8,   8,   8, conv2d_5
  8,   8,   8, batch_normalization_5
  8,   8,   8, leaky_re_lu_5
  8,   8,   8, max_pooling2d_5
  8,   8,   8, conv2d_6
  8,   8,   8, batch_normalization_6
  8,   8,   8, leaky_re_lu_6
  8,   8,   8, max_pooling2d_6
  8,   8,   8, conv2d_7
  8,   8,   8, batch_normalization_7
  8,   8,   8, leaky_re_lu_7
  8,   8,   8, conv2d_8
  8,   8,   8, batch_normalization_8
  8,   8,   8, leaky_re_lu_8
  8,   8,   8, conv2d_9
